{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow object detection API setup\n",
    "\n",
    "    - https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kishan.kumar\\DeepLearning_notebooks\\projects\\object_detection\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = os.getcwd()\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create Environment\n",
    "\n",
    "1. create conda environment `conda create -n object_detection tensorflow` & `conda activate object_detection`\n",
    "\n",
    "\n",
    "2. install dependent libraries\n",
    "    - protobuf: Protocol Buffers are a method of serializing structured data. inter program communication, data storage. \n",
    "    - Lxml: processing XML and HTML in python\n",
    "    - Matplotlib: graph plotting library\n",
    "    - numpy: numerical python library (Arrays)\n",
    "    - Pandas: data manipulation library (Dataframe)\n",
    "    - Cython: for C like performance from python\n",
    "    - Pillow: Python Imaging Library\n",
    "    - OpenCV-Python: for Computer Vision in python\n",
    "    \n",
    "    `pip install protobuf pillow lxml Cython jupyter matplotlib pandas opencv-python`  \n",
    "    \n",
    "    \n",
    "3. Download following\n",
    "    - [TensorFlow Object Detection API repository](https://github.com/tensorflow/models)\n",
    "    - [TensorFlow Model Zoo page](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md)\n",
    "    - [TensorFlow-Object-Detection-API-Tutorial](https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10)\n",
    "    - [LabelImg utility](https://github.com/tzutalin/labelImg#...)\n",
    "    \n",
    "    \n",
    "4. Folder Setup\n",
    "    - Extract models folder in project directory\n",
    "    - Rename model-master to models\n",
    "    - Extract `faster_rcnn_inception_v2_coco_2018_01_28` downloaded from model zoo page.\n",
    "    - Paste folder to the `C:\\tensorflow1\\models\\research\\object_detection` folder\n",
    "    - Extract `TensorFlow-Object-Detection-API-Tutorial` and paste files in object detection folder\n",
    "\n",
    "\n",
    "5. Delete the following files (do not delete the folders)\n",
    "    - All files in `\\object_detection\\images\\train` and `\\object_detection\\images\\test`\n",
    "    - The `test_labels.csv` and `train_labels.csv` files in `\\object_detection\\images`\n",
    "    - All files in `\\object_detection\\training`\n",
    "    - All files in `\\object_detection\\inference_graph`\n",
    "    \n",
    "    \n",
    "6. Configure PYTHONPATH environment variable  \n",
    "    `C:\\> set PYTHONPATH=C:\\object_detection;C:\\object_detection\\slim`\n",
    "    \n",
    "    \n",
    "7. Compile Protobufs and run setup.py  \n",
    "    `protoc --python_out=. .\\object_detection\\protos\\anchor_generator.proto .\\object_detection\\protos\\argmax_matcher.proto .\\object_detection\\protos\\bipartite_matcher.proto .\\object_detection\\protos\\box_coder.proto .\\object_detection\\protos\\box_predictor.proto .\\object_detection\\protos\\eval.proto .\\object_detection\\protos\\faster_rcnn.proto .\\object_detection\\protos\\faster_rcnn_box_coder.proto .\\object_detection\\protos\\grid_anchor_generator.proto .\\object_detection\\protos\\hyperparams.proto .\\object_detection\\protos\\image_resizer.proto .\\object_detection\\protos\\input_reader.proto .\\object_detection\\protos\\losses.proto .\\object_detection\\protos\\matcher.proto .\\object_detection\\protos\\mean_stddev_box_coder.proto .\\object_detection\\protos\\model.proto .\\object_detection\\protos\\optimizer.proto .\\object_detection\\protos\\pipeline.proto .\\object_detection\\protos\\post_processing.proto .\\object_detection\\protos\\preprocessor.proto .\\object_detection\\protos\\region_similarity_calculator.proto .\\object_detection\\protos\\square_box_coder.proto .\\object_detection\\protos\\ssd.proto .\\object_detection\\protos\\ssd_anchor_generator.proto .\\object_detection\\protos\\string_int_label_map.proto .\\object_detection\\protos\\train.proto .\\object_detection\\protos\\keypoint_box_coder.proto .\\object_detection\\protos\\multiscale_anchor_generator.proto .\\object_detection\\protos\\graph_rewriter.proto`\n",
    "    \n",
    "    __(Note: TensorFlow occassionally adds new .proto files to the \\protos folder. If you get an error saying ImportError: cannot import name 'something_something_pb2' , you may need to update the protoc command to include the new .proto files.)__\n",
    "\n",
    "    `C:\\object_detection> python setup.py build`  \n",
    "    `C:\\object_detection> python setup.py install`  \n",
    "    \n",
    "__*Tensorflow object detection API is now Ready*__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Configure TFOBJ API according to your requirements\n",
    "\n",
    "1. Collect and lable your data using labellmg utility  \n",
    "\n",
    "\n",
    "2. Generate Training Data (dir: object_detection)    \n",
    "    `python xml_to_csv.py` : This creates a train_labels.csv and test_labels.csv file in the \\object_detection\\images folder.  \n",
    "\n",
    "\n",
    "3. Next, open the `generate_tfrecord.py` file in a text editor. Replace the label map starting at line 31 with your own label map, where each object is assigned an ID number. This same number assignment will be used when configuring the `labelmap.pbtxt` file.\n",
    "\n",
    "\n",
    "    For example, say you are training a classifier to detect basketballs, shirts, and shoes. You will replace the following code in generate_tfrecord.py:\n",
    "\n",
    "\n",
    "`    #### TO-DO replace this with label map\n",
    "    def class_text_to_int(row_label):\n",
    "        if row_label == 'nine':\n",
    "            return 1\n",
    "        elif row_label == 'ten':\n",
    "            return 2\n",
    "        elif row_label == 'jack':\n",
    "            return 3\n",
    "        else:\n",
    "            return None`  \n",
    "    With this:\n",
    "\n",
    "`   #### TO-DO replace this with label map\n",
    "    def class_text_to_int(row_label):\n",
    "        if row_label == 'basketball':\n",
    "            return 1\n",
    "        elif row_label == 'shirt':\n",
    "            return 2\n",
    "        elif row_label == 'shoe':\n",
    "            return 3\n",
    "        else:\n",
    "            return None`\n",
    "            \n",
    "            \n",
    "4. Generate the TFRecord files by issuing these commands from the \\object_detection folder:\n",
    "\n",
    "    `python generate_tfrecord.py --csv_input=images\\train_labels.csv --image_dir=images\\train --output_path=train.record`  \n",
    "    `python generate_tfrecord.py --csv_input=images\\test_labels.csv --image_dir=images\\test --output_path=test.record`\n",
    "    \n",
    "    These generate a train.record and a test.record file in \\object_detection. These will be used to train the new object detection classifier.\n",
    "    \n",
    "    \n",
    "5. Create Label Map\n",
    "\n",
    "    The label map tells the trainer what each object is by defining a mapping of class names to class ID numbers. Use a text editor to create a new file and save it as labelmap.pbtxt in the C:\\tensorflow1\\models\\research\\object_detection\\training folder. (Make sure the file type is .pbtxt, not .txt !) In the text editor, copy or type in the label map in the format below (the example below is the label map for my Pinochle Deck Card Detector):\n",
    "\n",
    "`\n",
    "        item {\n",
    "          id: 1\n",
    "          name: 'nine'\n",
    "        }\n",
    "        item {\n",
    "          id: 2\n",
    "          name: 'ten'\n",
    "        }\n",
    "        item {\n",
    "          id: 3\n",
    "          name: 'jack'\n",
    "        }\n",
    "`\n",
    "\n",
    "    The label map ID numbers should be the same as what is defined in the generate_tfrecord.py file. For the basketball, shirt, and shoe detector example mentioned in Step 4, the labelmap.pbtxt file will look like:\n",
    "\n",
    "`\n",
    "        item {\n",
    "          id: 1\n",
    "          name: 'basketball'\n",
    "        }\n",
    "        item {\n",
    "          id: 2\n",
    "          name: 'shirt'\n",
    "        }\n",
    "        item {\n",
    "          id: 3\n",
    "          name: 'shoe'\n",
    "        }\n",
    "`\n",
    "\n",
    "6. Configure training\n",
    "    Finally, the object detection training pipeline must be configured. It defines which model and what parameters will be used for training. This is the last step before running training!\n",
    "\n",
    "    Navigate to C:\\tensorflow1\\models\\research\\object_detection\\samples\\configs and copy the faster_rcnn_inception_v2_pets.config file into the \\object_detection\\training directory. Then, open the file with a text editor. There are several changes to make to the .config file, mainly changing the number of classes and examples, and adding the file paths to the training data.\n",
    "\n",
    "    Make the following changes to the faster_rcnn_inception_v2_pets.config file. Note: The paths must be entered with single forward slashes (NOT backslashes), or TensorFlow will give a file path error when trying to train the model! Also, the paths must be in double quotation marks ( \" ), not single quotation marks ( ' ).\n",
    "\n",
    "    - Line 9. Change `num_classes` to the number of different objects you want the classifier to detect. For the above basketball, shirt, and shoe detector, it would be `num_classes : 3` .\n",
    "\n",
    "    - Line 110. Change fine_tune_checkpoint to:\n",
    "\n",
    "        `fine_tune_checkpoint : \"C:/tensorflow1/models/research/object_detection/faster_rcnn_inception_v2_coco_2018_01_28/model.ckpt\"`\n",
    "    - Lines 126 and 128. In the `train_input_reader` section, change `input_path` and `label_map_path` to:\n",
    "\n",
    "        `input_path : \"C:/tensorflow1/models/research/object_detection/train.record\"`\n",
    "        `label_map_path: \"C:/tensorflow1/models/research/object_detection/training/labelmap.pbtxt\"`\n",
    "    - Line 132. Change `num_examples` to the number of images you have in the `\\images\\test directory`.\n",
    "\n",
    "    - Lines 140 and 142. In the `eval_input_reader` section, change `input_path` and `label_map_path` to:\n",
    "\n",
    "        `input_path : \"C:/tensorflow1/models/research/object_detection/test.record\"`\n",
    "        `label_map_path: \"C:/tensorflow1/models/research/object_detection/training/labelmap.pbtxt\"`\n",
    "\n",
    "__Save the file after the changes have been made. That’s it! The training job is all configured and ready to go!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train your Model\n",
    "\n",
    "1. Run the Training\n",
    "\n",
    "    `python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/faster_rcnn_inception_v2_pets.config`\n",
    "    \n",
    "    \n",
    "2. Export Inference Graph\n",
    "\n",
    "    Now that training is complete, the last step is to generate the frozen inference graph (.pb file). From the \\object_detection folder, issue the following command, where __“XXXX”__ in “model.ckpt-XXXX” should be replaced with the highest-numbered .ckpt file in the training folder:\n",
    "    \n",
    "    `python export_inference_graph.py --input_type image_tensor --pipeline_config_path training/faster_rcnn_inception_v2_pets.config --trained_checkpoint_prefix training/model.ckpt-XXXX --output_directory inference_graph`\n",
    "\n",
    "\n",
    "3. Use Your Newly Trained Object Detection Classifier!\n",
    "\n",
    "    The object detection classifier is all ready to go! I’ve written Python scripts to test it out on an image, video, or webcam feed.\n",
    "\n",
    "    Before running the Python scripts, you need to modify the NUM_CLASSES variable in the script to equal the number of classes you want to detect. (For my Pinochle Card Detector, there are six cards I want to detect, so NUM_CLASSES = 6.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
